{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visión por computadora II\n",
    "## Trabajo Práctico Integrador\n",
    "\n",
    "## Inferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "from time import time\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "import dill as pickle\n",
    "\n",
    "from plotly import graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import fbeta_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms as T, models\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el directorio de salida si no existe\n",
    "path_output = \"../output\"\n",
    "if not os.path.exists(path_output):\n",
    "    os.makedirs(path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el directorio de logs si no existe para guardar los logs de tensorboard\n",
    "logs_dir = '../logs'\n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Si tenemos disponible GPU, lo usamos\n",
    "# Chequeamos si tenemos disponible GPU (CUDA)\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# Chequeamos si tenemos disponible aceleración por hardware en un chip de Apple (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "# Por defecto usamos CPU\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semilla para reproducibilidad de los experimentos\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos el dataset test preprocesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test files: 11466, \n"
     ]
    }
   ],
   "source": [
    "path = \"../data\"\n",
    "\n",
    "# Esto es asi ya que no olvidemos que usamos el dataset de train y lo dividimos \n",
    "# en train, valid y test o sea que todas las imagenes estan en el path_train\n",
    "path_test = os.path.join(path, \"train\") # \n",
    "\n",
    "print(\n",
    "    f\"test files: {len(os.listdir(path_test))}, \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2291, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Aerosols</th>\n",
       "      <th>Aluminum can</th>\n",
       "      <th>Cardboard</th>\n",
       "      <th>Cellulose</th>\n",
       "      <th>Ceramic</th>\n",
       "      <th>Container for household chemicals</th>\n",
       "      <th>Disposable tableware</th>\n",
       "      <th>Electronics</th>\n",
       "      <th>Furniture</th>\n",
       "      <th>...</th>\n",
       "      <th>Plastic toys</th>\n",
       "      <th>Postal packaging</th>\n",
       "      <th>Printing industry</th>\n",
       "      <th>Scrap metal</th>\n",
       "      <th>Stretch film</th>\n",
       "      <th>Tetra pack</th>\n",
       "      <th>Textile</th>\n",
       "      <th>Tin</th>\n",
       "      <th>Unknown plastic</th>\n",
       "      <th>Zip plastic bag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ccff6c6-AluCan257_jpg.rf.a8f53f21395d0d5757d7...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59b34896-R_2091_jpg.rf.a967d601319609446bd2cd5...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d254face-R_4159_jpg.rf.a95781333b43a5c8c62d42b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eb559464-O_13694_jpg.rf.a8ece945730b0647388b64...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0d43474a-R_1215_jpg.rf.a98e6508a5ea28fc11d6868...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename   Aerosols  \\\n",
       "0  2ccff6c6-AluCan257_jpg.rf.a8f53f21395d0d5757d7...          0   \n",
       "1  59b34896-R_2091_jpg.rf.a967d601319609446bd2cd5...          0   \n",
       "2  d254face-R_4159_jpg.rf.a95781333b43a5c8c62d42b...          0   \n",
       "3  eb559464-O_13694_jpg.rf.a8ece945730b0647388b64...          0   \n",
       "4  0d43474a-R_1215_jpg.rf.a98e6508a5ea28fc11d6868...          0   \n",
       "\n",
       "    Aluminum can   Cardboard   Cellulose   Ceramic  \\\n",
       "0              1           0           0         0   \n",
       "1              1           0           0         0   \n",
       "2              0           0           0         0   \n",
       "3              0           0           0         0   \n",
       "4              0           0           0         0   \n",
       "\n",
       "    Container for household chemicals   Disposable tableware   Electronics  \\\n",
       "0                                   0                      0             0   \n",
       "1                                   0                      0             0   \n",
       "2                                   0                      0             0   \n",
       "3                                   0                      0             0   \n",
       "4                                   0                      0             0   \n",
       "\n",
       "    Furniture  ...   Plastic toys   Postal packaging   Printing industry  \\\n",
       "0           0  ...              0                  0                   0   \n",
       "1           0  ...              0                  0                   0   \n",
       "2           0  ...              0                  0                   0   \n",
       "3           0  ...              0                  0                   0   \n",
       "4           0  ...              0                  0                   0   \n",
       "\n",
       "    Scrap metal   Stretch film   Tetra pack   Textile   Tin   Unknown plastic  \\\n",
       "0             0              0            0         0     0                 0   \n",
       "1             0              0            0         0     0                 0   \n",
       "2             0              0            0         0     0                 0   \n",
       "3             0              0            0         0     0                 0   \n",
       "4             0              0            0         0     0                 0   \n",
       "\n",
       "    Zip plastic bag  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos el dataset de test\n",
    "path_test_class = os.path.join(path, \"test_dataset_preprocesado.csv\")\n",
    "df_test = pd.read_csv(path_test_class)\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones de creación de dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_transforms():\n",
    "    transform_train = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Resize(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], # Media extraída de ImageNet\n",
    "            std=[0.229, 0.224, 0.225], # Desviación estándar extraída de ImageNet\n",
    "        )\n",
    "    ])\n",
    "    transform_val = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Resize(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], # Media extraída de ImageNet\n",
    "            std=[0.229, 0.224, 0.225], # Desviación estándar extraída de ImageNet\n",
    "        )\n",
    "    ])\n",
    "    return transform_train, transform_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloWasteDatasetError(Exception):\n",
    "    pass\n",
    "\n",
    "class YoloWasteDataset(Dataset):\n",
    "    def __init__(self, df, ohe_tags, transform, path, is_train=True, idx_tta=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.ohe_tags = ohe_tags\n",
    "        self.transform = transform\n",
    "        if isinstance(path, str):\n",
    "            self.paths = [path]\n",
    "        elif isinstance(path, (list, tuple)):\n",
    "            self.paths = path\n",
    "        else:\n",
    "            raise YoloWasteDatasetError(f\"Path type must be str, list or tuple, got: {type(path)}\")\n",
    "        self.is_train = is_train\n",
    "        if not is_train:\n",
    "            if not idx_tta in list(range(6)):\n",
    "                raise YoloWasteDatasetError(\n",
    "                    f\"In test mode, 'idx_tta' must be an int belonging to [0, 5], got: {repr(idx_tta)}\"\n",
    "                )\n",
    "            self.idx_tta = idx_tta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.df.iloc[idx, 0] # Asumiendo que la primer columna es filename\n",
    "        for path in self.paths:\n",
    "            if filename in os.listdir(path):\n",
    "                file_path = os.path.join(path, filename)\n",
    "                break\n",
    "        else:\n",
    "            raise YoloWasteDatasetError(f\"Can't fetch {filename} among {self.paths}\")\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = self.ohe_tags[idx]\n",
    "        return img, label\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        imgs, labels = [], []\n",
    "        for (img, label) in batch:\n",
    "            img = self.custom_augment(img)\n",
    "            img = torch.tensor(img)\n",
    "            img = img.permute(2, 0, 1)\n",
    "            img = self.transform(img)\n",
    "            imgs.append(img[None])\n",
    "            labels.append(label)\n",
    "        imgs = torch.cat(imgs).float().to(device)\n",
    "        labels = torch.tensor(labels).float().to(device)\n",
    "        return imgs, labels\n",
    "\n",
    "    def load_img(self, idx, ax=None):\n",
    "        img, ohe_label = self[idx]\n",
    "        label = self.df.iloc[idx]\n",
    "        title = f\"{label} - {ohe_label}\"\n",
    "        if ax is None:\n",
    "            plt.imshow(img)\n",
    "            plt.title(title)\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(title)\n",
    "    \n",
    "    def custom_augment(self, img):\n",
    "        \"\"\"\n",
    "        Discrete rotation and horizontal flip.\n",
    "        Random during training and non random during testing for TTA.\n",
    "        Not implemented in torchvision.transforms, hence this function.\n",
    "        \"\"\"\n",
    "        choice = np.random.randint(0, 6) if self.is_train else self.idx_tta\n",
    "        if choice == 0:\n",
    "            # Rotate 90\n",
    "            img = cv2.rotate(img, rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
    "        if choice == 1:\n",
    "            # Rotate 90 and flip horizontally\n",
    "            img = cv2.rotate(img, rotateCode=cv2.ROTATE_90_CLOCKWISE)\n",
    "            img = cv2.flip(img, flipCode=1)\n",
    "        if choice == 2:\n",
    "            # Rotate 180\n",
    "            img = cv2.rotate(img, rotateCode=cv2.ROTATE_180)\n",
    "        if choice == 3:\n",
    "            # Rotate 180 and flip horizontally\n",
    "            img = cv2.rotate(img, rotateCode=cv2.ROTATE_180)\n",
    "            img = cv2.flip(img, flipCode=1)\n",
    "        if choice == 4:\n",
    "            # Rotate 90 counter-clockwise\n",
    "            img = cv2.rotate(img, rotateCode=cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        if choice == 5:\n",
    "            # Rotate 90 counter-clockwise and flip horizontally\n",
    "            img = cv2.rotate(img, rotateCode=cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "            img = cv2.flip(img, flipCode=1)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones auxiliares para la inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def batch_predict(model, X):\n",
    "    model.eval()\n",
    "    Y = model(X)\n",
    "    return Y.detach().float().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(df_test, path_test, batch_size, idx_tta):\n",
    "    transform_train, transform_val = obtener_transforms()\n",
    "    ohe_tags_test = df_test.iloc[:, 1:].values\n",
    "    #ohe_tags_test = df_test.iloc[:, 1:].values.astype(np.float32)\n",
    "    ds_test = YoloWasteDataset(df_test, ohe_tags_test, transform_val, path=path_test, is_train=False, idx_tta=idx_tta)\n",
    "    dl_test = DataLoader(ds_test, batch_size=batch_size, shuffle=False, collate_fn=ds_test.collate_fn)\n",
    "    return dl_test, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculamos el puntaje final del modelo ResNet18 con los datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferencia del Modelo resNet18 usando datos de prueba usando TTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculamos el puntaje final del modelo EfficientNet-B0 con los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cargamos el modelo EfficientNet-B0 best\n",
    "# model_e = torch.load(os.path.join(path_output, \"efficientnet_b0_BEST_fold2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_e.eval() # Cambiamos el modelo a modo de evaluación\n",
    "\n",
    "# # Definimos el umbral\n",
    "# threshs = 0.2\n",
    "\n",
    "# # Cargar los datos de prueba\n",
    "# batch_size = 64\n",
    "# Y_hat_test = []\n",
    "# for idx_tta in range(6): # Realizamos TTA\n",
    "#     Y_hat_test_tta = []\n",
    "#     dl_test, df_test = get_test_data(df_test, path_test, batch_size, idx_tta) # Cargamos los datos de prueba\n",
    "#     for X, _ in tqdm(dl_test, leave=False):\n",
    "#         Y_hat_test_batch = batch_predict(model_e, X)\n",
    "#         Y_hat_test_tta.extend(Y_hat_test_batch)\n",
    "#     Y_hat_test.append(Y_hat_test_tta)\n",
    "# Y_hat_test = np.mean(np.array(Y_hat_test), axis=0)\n",
    "# Y_hat_test = (Y_hat_test > threshs).astype(float)\n",
    "\n",
    "# # Guardar los resultados de la inferencia\n",
    "# df_test['predicted_labels'] = list(Y_hat_test)\n",
    "# output_path = os.path.join(path_output, 'efficientnet_BEST_predicciones_test.csv')\n",
    "# df_test.to_csv(output_path, index=False)\n",
    "# print(f\"Predicciones guardadas en {output_path}\")\n",
    "\n",
    "# # Calcular y mostrar el fbeta_score\n",
    "# Y_test = df_test.iloc[:, 1:-1].values  # Etiquetas reales, sin la columna de nombres de archivo y etiquetas predichas\n",
    "# final_score = fbeta_score(Y_test, Y_hat_test, beta=2, average=\"samples\")\n",
    "# print(f\"Puntaje final de Fbeta en el conjunto de pruebas para Efficientnet_BEST con TTA: {final_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_fbeta_score(model_r, df_test, path_test, batch_size, path_output, threshs=0.2, tta_steps=6, beta=2):\n",
    "    model_r.eval()  # Cambiamos el modelo a modo de evaluación\n",
    "\n",
    "    # Definimos el umbral\n",
    "    threshs = threshs\n",
    "\n",
    "    # Inicializamos las predicciones\n",
    "    Y_hat_test = []\n",
    "    for idx_tta in range(tta_steps):  # Realizamos TTA\n",
    "        Y_hat_test_tta = []\n",
    "        dl_test, df_test = get_test_data(df_test, path_test, batch_size, idx_tta)  # Cargamos los datos de prueba\n",
    "        for X, _ in tqdm(dl_test, leave=False):\n",
    "            Y_hat_test_batch = batch_predict(model_r, X)\n",
    "            Y_hat_test_tta.extend(Y_hat_test_batch)\n",
    "        Y_hat_test.append(Y_hat_test_tta)\n",
    "    \n",
    "    Y_hat_test = np.mean(np.array(Y_hat_test), axis=0)\n",
    "    Y_hat_test = (Y_hat_test > threshs).astype(float)\n",
    "\n",
    "    # Guardar los resultados de la inferencia\n",
    "    df_test['predicted_labels'] = list(Y_hat_test)\n",
    "    output_path = os.path.join(path_output, 'predicciones_test.csv')\n",
    "    df_test.to_csv(output_path, index=False)\n",
    "    print(f\"Predicciones guardadas en {output_path}\")\n",
    "\n",
    "    # Calcular y mostrar el fbeta_score\n",
    "    Y_test = df_test.iloc[:, 1:-1].values  # Etiquetas reales, sin la columna de nombres de archivo y etiquetas predichas\n",
    "    final_score = fbeta_score(Y_test, Y_hat_test, beta=beta, average=\"samples\")\n",
    "    print(f\"Puntaje final de Fbeta en el conjunto de pruebas con TTA: {final_score}\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "# calcular_fbeta_score(modelo_efficientnet, df_test, path_test, batch_size, path_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo EfficientNet-B0 best\n",
    "model_r = torch.load(os.path.join(path_output, \"efficientnet_b0_BEST_fold2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo EfficientNet-B0 best\n",
    "model_e = torch.load(os.path.join(path_output, \"efficientnet_b0_BEST_fold2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29d238ba90d444ba11fafed93e1c2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55687/2880513708.py:50: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  labels = torch.tensor(labels).float().to(device)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfbdcce845e4474b8c49e08034c50cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd53e5dfea441f8a7bb08f60a29ad8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6ce72c29da4d8c86230846ac7e9f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d78123bc099437abdf51d7038ea7df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ded30d52234ece8f7f0452da36329e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones guardadas en ../output/predicciones_test.csv\n",
      "Puntaje final de Fbeta en el conjunto de pruebas con TTA: 0.9878337143723438\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64\n",
    "calcular_fbeta_score(model_r, df_test, path_test, batch_size, path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d253c75c48454cda8518bfba872c2d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcalcular_fbeta_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m, in \u001b[0;36mcalcular_fbeta_score\u001b[0;34m(model_r, df_test, path_test, batch_size, path_output, threshs, tta_steps, beta)\u001b[0m\n\u001b[1;32m     10\u001b[0m Y_hat_test_tta \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m dl_test, df_test \u001b[38;5;241m=\u001b[39m get_test_data(df_test, path_test, batch_size, idx_tta)  \u001b[38;5;66;03m# Cargamos los datos de prueba\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_hat_test_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_hat_test_tta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_hat_test_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch221/lib/python3.11/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch221/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch221/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch221/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch221/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 50\u001b[0m, in \u001b[0;36mYoloWasteDataset.collate_fn\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     48\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m     49\u001b[0m imgs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(imgs)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 50\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m imgs, labels\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "calcular_fbeta_score(model_e, df_test, path_test, batch_size, path_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
